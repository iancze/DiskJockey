var documenterSearchIndex = {"docs":
[{"location":"RADMC3D_setup.html#RADMC3D-setup","page":"RADMC Setup","title":"RADMC3D setup","text":"","category":"section"},{"location":"RADMC3D_setup.html","page":"RADMC Setup","title":"RADMC Setup","text":"This is a brief overview of some of the options that are set for RADMC-3D. For most DiskJockey use, the user need only be concerned about the gridding setup. However, some of the files written out to interface with RADMC-3D are documented here for reference.","category":"page"},{"location":"RADMC3D_setup.html#Gridding","page":"RADMC Setup","title":"Gridding","text":"","category":"section"},{"location":"RADMC3D_setup.html","page":"RADMC Setup","title":"RADMC Setup","text":"Most models are specified (mathematically) as 2D axisymmetric in cylindrical coordinates. RADMC-3D takes files in spherical coordinates, and so this conversion is done in model.jl as the model is written out.","category":"page"},{"location":"RADMC3D_setup.html","page":"RADMC Setup","title":"RADMC Setup","text":"Generally, the grid cells are logarithmically spaced in radius. The elevation (theta) cells are logarithmically spaced in theta, with cells clustered more denesly near the midplane than at the poles. Because of the axisymmetry, there is only one phi (azimuth) cell.","category":"page"},{"location":"RADMC3D_setup.html","page":"RADMC Setup","title":"RADMC Setup","text":"Although RADMC-3D has the ability to determine dust temperatures through radiative Monte Carlo, we set the gas temperatures directly though a simple radial temperature profile.","category":"page"},{"location":"RADMC3D_setup.html","page":"RADMC Setup","title":"RADMC Setup","text":"Then, the user also chooses the number of pixels npix for the resulting image to have. A good rule of thumb is that pixels need to be roughly 5-10x smaller than the resolution of the interferometric observations.","category":"page"},{"location":"RADMC3D_setup.html#Files-required-for-line-transfer-and-what-they-are","page":"RADMC Setup","title":"Files required for line transfer and what they are","text":"","category":"section"},{"location":"RADMC3D_setup.html","page":"RADMC Setup","title":"RADMC Setup","text":"lines.inp: control file for line transfer\nmolecule_co.inp contains properties of atom or molecule\nnumberdens_co.inp number density of molecule in units of cm^{-3}\ngas_temperature.inp gas temperature at each grid cell","category":"page"},{"location":"RADMC3D_setup.html#radmc.inp","page":"RADMC Setup","title":"radmc.inp","text":"","category":"section"},{"location":"RADMC3D_setup.html","page":"RADMC Setup","title":"RADMC Setup","text":"tgas_eq_tdust=0 #this means we will specify the gas temperature at each grid cell, rather than setting it equal to the dust temperature.","category":"page"},{"location":"RADMC3D_setup.html#lines.inp","page":"RADMC Setup","title":"lines.inp","text":"","category":"section"},{"location":"RADMC3D_setup.html","page":"RADMC Setup","title":"RADMC Setup","text":"Format styles","category":"page"},{"location":"RADMC3D_setup.html","page":"RADMC Setup","title":"RADMC Setup","text":"1 #format style 1 (may be 2)\n1\nco    leiden    0    0","category":"page"},{"location":"RADMC3D_setup.html","page":"RADMC Setup","title":"RADMC Setup","text":"This means that we will only be using the CO molecule. All of the information about this molecule is stored in the file molecule_co.inp. This is read from the Leiden database. Basically it provides all of the quantum information about the energy levels.","category":"page"},{"location":"RADMC3D_setup.html#numberdens_XXX.inp","page":"RADMC Setup","title":"numberdens_XXX.inp","text":"","category":"section"},{"location":"RADMC3D_setup.html","page":"RADMC Setup","title":"RADMC Setup","text":"The number density of each species per cubic centimeter.","category":"page"},{"location":"RADMC3D_setup.html#gas_temperature.inp","page":"RADMC Setup","title":"gas_temperature.inp","text":"","category":"section"},{"location":"RADMC3D_setup.html","page":"RADMC Setup","title":"RADMC Setup","text":"Specifies the gas temperature at each cell.","category":"page"},{"location":"RADMC3D_setup.html#gas_velocity.inp","page":"RADMC Setup","title":"gas_velocity.inp","text":"","category":"section"},{"location":"RADMC3D_setup.html","page":"RADMC Setup","title":"RADMC Setup","text":"Three numbers at each grid point, which are the components of velocity along each direction. All components have units of cm/s.","category":"page"},{"location":"RADMC3D_setup.html#microturbulence.inp","page":"RADMC Setup","title":"microturbulence.inp","text":"","category":"section"},{"location":"RADMC3D_setup.html","page":"RADMC Setup","title":"RADMC Setup","text":"We can also specify a microturbulent broadening for each cell.","category":"page"},{"location":"RADMC3D_setup.html#partitionfunction_XXX.inp","page":"RADMC Setup","title":"partitionfunction_XXX.inp","text":"","category":"section"},{"location":"RADMC3D_setup.html","page":"RADMC Setup","title":"RADMC Setup","text":"This can be specified for CO or other species. Otherwise RADMC3D will calculate the partition function itself using the molecular data file.","category":"page"},{"location":"RADMC3D_setup.html#amr_grid.inp","page":"RADMC Setup","title":"amr_grid.inp","text":"","category":"section"},{"location":"RADMC3D_setup.html","page":"RADMC Setup","title":"RADMC Setup","text":"We can use different coordinate systems here.","category":"page"},{"location":"RADMC3D_setup.html","page":"RADMC Setup","title":"RADMC Setup","text":"**coordsystem**:\n< 100: cartesian\n100<= - <200: spherical\n200<= - <300: cylindrical","category":"page"},{"location":"RADMC3D_setup.html","page":"RADMC Setup","title":"RADMC Setup","text":"If we want to make a spherical grid, using 2D symmetry, we can specify that we wish one dimension to be non-active.","category":"page"},{"location":"RADMC3D_setup.html","page":"RADMC Setup","title":"RADMC Setup","text":"The files that need to be generated by our package are","category":"page"},{"location":"RADMC3D_setup.html","page":"RADMC Setup","title":"RADMC Setup","text":"amr_grid.inp: location of grid cells\nmicroturbulence.inp: microturbulence at each cell\ngas_velocity.inp: three component velocity vector at each cell\nnumberdens_co.inp: the number density of the CO molecule at each cell","category":"page"},{"location":"RADMC3D_setup.html","page":"RADMC Setup","title":"RADMC Setup","text":"All of the other files can be pre-generated or lifted from some database.","category":"page"},{"location":"installation.html#Installation","page":"Installation","title":"Installation","text":"","category":"section"},{"location":"installation.html#Julia","page":"Installation","title":"Julia","text":"","category":"section"},{"location":"installation.html","page":"Installation","title":"Installation","text":"First, you should to install the Julia programming language on your machine. Depending on how you choose to install Julia, you may need to take the additional step of adding the Julia executable to your PATH.","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"Julia uses \"environments\" to manage package dependencies. These are similar in concept to Python's virtual environments, and very useful in practice. If you are unfamiliar, it is highly recommended to read through the Julia environment documentation here, since they are used to install DiskJockey in the recommended configuration. ","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"To get started, create a new folder that you will contain your work for a particular project.","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"$ mkdir myproject","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"Then, start Julia, and use the interactive package manager Pkg (enter via ]) to create an environment specific to this project. ","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"$ cd myproject\n$ julia \njulia> ]\npkg> activate . \nActivating new environment at `~/myproject/Project.toml`\n(myproject) pkg>","category":"page"},{"location":"installation.html#DiskJockey-Package","page":"Installation","title":"DiskJockey Package","text":"","category":"section"},{"location":"installation.html","page":"Installation","title":"Installation","text":"Next, we will install the DiskJockey package to this same Julia environment. DiskJockey is not (yet) registered an official Julia package, so it needs to be installed by using the link to the github repository. ","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"(myproject) pkg> add https://github.com/iancze/DiskJockey.git","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"This process may take a few minutes as the relevant packages (including RADMC-3D) are downloaded from the web and installed. If you run into errors in this build process, please file an issue on the github repository so that we may try to fix this. If you already have RADMC-3D installed on your system, this process won't interfere with that installation, DiskJockey will use the version of RADMC-3D it downloaded during the build process. ","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"It is a good idea to set the environment variable JULIA_PROJECT to the location for this project","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"export JULIA_PROJECT='/home/ian/myproject'","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"You can add this line to your .bashrc or shell startup, or local directory initialization script. That way, whenever you start Julia, it will already activate the myproject environment. This makes running the scripts in the next section much easier. Advanced users with multiple active Julia projects may wish to explore alternate package activation patterns.","category":"page"},{"location":"installation.html#DiskJockey-Scripts","page":"Installation","title":"DiskJockey Scripts","text":"","category":"section"},{"location":"installation.html#Julia-Scripts","page":"Installation","title":"Julia Scripts","text":"","category":"section"},{"location":"installation.html","page":"Installation","title":"Installation","text":"Included within the DiskJockey github repo are several \"driver\" command line scripts in the DiskJockey/scripts directory that you can use to perform the actual mass fitting and analysis plotting. To utilize these files, you should add the scripts directory to your system PATH. To figure out where the package is installed","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"julia> using DiskJockey\njulia> dirname(pathof(DiskJockey))\n\"/home/ian/.julia/dev/DiskJockey/src\"","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"Your PATH will vary. The scripts are located inside of the DiskJockey/scripts directory, so if you are using bash, you will want to add the PATH that looks something like","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"export PATH=\"/home/ian/.julia/dev/DiskJockey/scripts:$PATH\"","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"inside of your .bashrc file.","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"The scripts depend on other Julia packages for reading configuration files (in YAML) and plotting. You can either install these packages to your myproject environment just like you did DiskJockey, or you can use the convenience script ","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"$ DJ_initialize_environment.jl","category":"page"},{"location":"installation.html#Python-Scripts","page":"Installation","title":"Python Scripts","text":"","category":"section"},{"location":"installation.html","page":"Installation","title":"Installation","text":"Some of the Python scripts also depend on imports from this directory, so you will also need to add","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"export PYTHONPATH=\"/home/ian/.julia/dev/DiskJockey/scripts:$PYTHONPATH\"","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"inside of your .bashrc file. ","category":"page"},{"location":"installation.html#Python-scripts","page":"Installation","title":"Python scripts","text":"","category":"section"},{"location":"installation.html","page":"Installation","title":"Installation","text":"Some of the analysis scripts and IO routines require Python 3.x and several Python packages. Please install the following packages via your own package manager or a distribution like anaconda:","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"numpy\nscipy\nmatplotlib\nh5py\nPyYAML\nJupyter/IPython\ncorner.py","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"With the package successfully installed, see the documentation in the docs/ folder on how to get started fitting a specific source, in particular the Cookbook.","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"If you'd like to run the test suite to make sure everything checks out, start Julia and run","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"julia> ]\n(@v1.4) pkg> activate .\n(@v1.4) pkg> test","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"this may take about 10 minutes or so. If you catch any errors for your specific machine, please report them via an Issue on the github repository.","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"The code package is designed to interface with visibilities in the UVHDF5 format, described here. UVHDF5 also provides scripts to convert to and from UVFITS and CASA measurement sets.","category":"page"},{"location":"installation.html#Development-workflow","page":"Installation","title":"Development workflow","text":"","category":"section"},{"location":"installation.html","page":"Installation","title":"Installation","text":"If you anticipate editing the source code, rather than installing the package with the add command, you can install using the develop command","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"julia> ] \n(@v1.4) pkg> develop https://github.com/iancze/DiskJockey.git","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"For archival purposes, tagged release versions of this package are available here.","category":"page"},{"location":"models.html#Models","page":"Models","title":"Models","text":"","category":"section"},{"location":"models.html","page":"Models","title":"Models","text":"DiskJockey supports many different disk models, and is designed in such a way so as to be easily extensible to new ones.","category":"page"},{"location":"models.html","page":"Models","title":"Models","text":"The current models include","category":"page"},{"location":"models.html#Standard","page":"Models","title":"Standard","text":"","category":"section"},{"location":"models.html","page":"Models","title":"Models","text":"Keyword: standard","category":"page"},{"location":"models.html","page":"Models","title":"Models","text":"This is a standard model that is used in Czekala et al. 2015 and 2016, and Rosenfeld et al. 2012.","category":"page"},{"location":"models.html#Vertical","page":"Models","title":"Vertical","text":"","category":"section"},{"location":"models.html","page":"Models","title":"Models","text":"Keyword: vertical","category":"page"},{"location":"models.html","page":"Models","title":"Models","text":"This model includes a more realistic temperature profile as outlined in Dartois et al. 2003, Rosenfeld et al. 2013, and Williams and Best 2014, among many others. We follow the specific parameterization in Williams and Best 2014.","category":"page"},{"location":"models.html","page":"Models","title":"Models","text":"The primary additional step for this model is the necessity to numerically solve the hydrostatic equilibrium equation (WB14 Eqn 1).","category":"page"},{"location":"models.html","page":"Models","title":"Models","text":"for a given radius, r, come up with a vertical grid of z points that stretches from the midplane to an appropriate height where the gas density is approximately zero.\ncalculate ln(rho(r,z)) as a function of (r, z) by integrating WB14 Eqn 1 using quadgk. This is the unnormalized density of the disk, which means the relative values at a fixed radius should be correct, but no guarantees about anything else. We will call the unnormalized density un_rho(r,z).\nnow, we know that Sigma(r) specifies the surface density of the disk, i.e., or the integral of rho(r, z) from z = -inf to +inf. Therefore, we can find rho(r,z) by vertically integrating un_rho(r,z) and finding the normalization constant, norm(r). Because we are dealing with integrals of very big and very small numbers, we need to do some tricks to avoid overflow and underflow errors.\nfinally, we know that CO is photodissociated when it is not shielded by enough gas, i.e., there is not enough gas column density above this height to block harmful radiation. Therefore, we need to find the photodissociation height, z_phot(r), above which the molecule CO can no longer exist. To do this requires integrating from z = +inf towards the midplane (z = 0) to find the height at which we have accumulated enough gas column density to be shielded.","category":"page"},{"location":"models.html","page":"Models","title":"Models","text":"This sounds like a lot of steps just to evaluate a single rho(r,z) point. Because RADMC-3D solves the radiative transfer on a spherical grid and the disk model is defined on a cylindrical grid, there is a careful order of operations necessary to achieve the appropriate accuracy in the shortest amount of computational time. We address this by first solving everything on a cylindrical grid to find norm(r) and z_phot(r) as a function of disk radius. Then, for a given (r_spherical, theta) point, we convert to cylindrical coordinates and solve WB14 Eqn 1 to find un_rho(r,z).","category":"page"},{"location":"models.html#VerticalEta","page":"Models","title":"VerticalEta","text":"","category":"section"},{"location":"models.html","page":"Models","title":"Models","text":"Characterized with ParametersVerticalEta. In addition to the parameters described in the Vertical model, this extension has an additional parameter eta, designed to vary the height of the atmosphere with radius.","category":"page"},{"location":"models.html#Nuker","page":"Models","title":"Nuker","text":"","category":"section"},{"location":"models.html","page":"Models","title":"Models","text":"The Nuker profile as used in Tripathi et al. 2017..","category":"page"},{"location":"api.html#API","page":"API","title":"API","text":"","category":"section"},{"location":"api.html","page":"API","title":"API","text":"For those interested in the source code, the most important files to start browsing are","category":"page"},{"location":"api.html","page":"API","title":"API","text":"model.jl: Contains the specification of the parametric disk model, as well as the tools to write to disk the synthesis files RADMC-3D requires.","category":"page"},{"location":"api.html","page":"API","title":"API","text":"image.jl: Contains type definitions to read images produced by RADMC-3D, as well as convert from physical coordinates to sky coordinates.","category":"page"},{"location":"api.html","page":"API","title":"API","text":"visibilities.jl: Contains type definitions to hold the dataset and the model visibilities. Additionally contains functions to apply phase shifts to the visibilities corresponding to shifts in the image plane. Also contains functions to FFT images to the visibility plane.","category":"page"},{"location":"api.html","page":"API","title":"API","text":"gridding.jl: Contains the prolate-spheroidal wave function definitions from Schwab 1984, used when doing the visibility interpolations.","category":"page"},{"location":"api.html","page":"API","title":"API","text":"venus.jl: This implementation uses the Ensemble Sampler (a Julia port of Dan Foreman-Mackey's emcee python package) to sample the posterior distribution using parallelized walkers.","category":"page"},{"location":"api.html#Constants","page":"API","title":"Constants","text":"","category":"section"},{"location":"api.html","page":"API","title":"API","text":"constants.fftspace(width::Real, N::Int)","category":"page"},{"location":"api.html#DiskJockey.constants.fftspace-Tuple{Real, Int64}","page":"API","title":"DiskJockey.constants.fftspace","text":"Oftentimes it is necessary to get a symmetric coordinate array that spans N  elements from -width to +width, but makes sure that the middle point lands  on 0. The indices go from 0 to N -1  linspace returns  the end points inclusive, wheras we want to leave out the  right endpoint, because we are sampling the function in a cyclic manner.\n\n\n\n\n\n","category":"method"},{"location":"api.html#model.jl","page":"API","title":"model.jl","text":"","category":"section"},{"location":"api.html","page":"API","title":"API","text":"Modules = [model]","category":"page"},{"location":"api.html#DiskJockey.model.registered_params","page":"API","title":"DiskJockey.model.registered_params","text":"A dictionary of parameter lists for conversion.\n\n\n\n\n\n","category":"constant"},{"location":"api.html#DiskJockey.model.Grid","page":"API","title":"DiskJockey.model.Grid","text":"Define a grid object which stores all of these variables This will not change for the duration of the run.\n\n\n\n\n\n","category":"type"},{"location":"api.html#DiskJockey.model.Grid-2","page":"API","title":"DiskJockey.model.Grid","text":"Create a grid object using a logarithmic then linear then logarithmic radial spacing\n\n\n\n\n\n","category":"type"},{"location":"api.html#DiskJockey.model.Grid-Tuple{Dict}","page":"API","title":"DiskJockey.model.Grid","text":"Read from a dictionary, then choose how to make the grid based upon the arguments.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.model.Grid-Tuple{Int64, Int64, Int64, Real, Real}","page":"API","title":"DiskJockey.model.Grid","text":"Hold the ray-tracing grid.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.model.Grid-Tuple{Int64, Int64, Real, Real}","page":"API","title":"DiskJockey.model.Grid","text":"Hold the ray-tracing grid.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.model.ParametersNuker","page":"API","title":"DiskJockey.model.ParametersNuker","text":"Parameters for the NUKER model.\n\n\n\n\n\n","category":"type"},{"location":"api.html#DiskJockey.model.ParametersStandard","page":"API","title":"DiskJockey.model.ParametersStandard","text":"Parameters for the standard model.\n\n\n\n\n\n","category":"type"},{"location":"api.html#DiskJockey.model.ParametersVertical","page":"API","title":"DiskJockey.model.ParametersVertical","text":"Parameters for the vertical model.\n\n\n\n\n\n","category":"type"},{"location":"api.html#DiskJockey.model.ParametersVerticalEta","page":"API","title":"DiskJockey.model.ParametersVerticalEta","text":"Parameters for the vertical model with variable slope.\n\n\n\n\n\n","category":"type"},{"location":"api.html#DiskJockey.model.Sigma-Tuple{Float64, DiskJockey.model.ParametersNuker}","page":"API","title":"DiskJockey.model.Sigma","text":"Sigma(r::Float64, pars::ParametersNuker)\n\nCalculate the gas surface density using the Nuker profile.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.model.Sigma-Tuple{Float64, Union{DiskJockey.model.ParametersStandard, DiskJockey.model.ParametersVertical, DiskJockey.model.ParametersVerticalEta}}","page":"API","title":"DiskJockey.model.Sigma","text":"Calculate the gas surface density\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.model.convert_dict-Tuple{Dict, AbstractString}","page":"API","title":"DiskJockey.model.convert_dict","text":"Used to turn a dictionary of parameter values (from config.yaml) directly into a parameter type. Generally used for synthesis and plotting command line scripts.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.model.convert_vector-Tuple{Vector{Float64}, AbstractString, Vector{T} where T}","page":"API","title":"DiskJockey.model.convert_vector","text":"Unroll a vector of parameter values into a parameter type.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.model.generate_vel_mask-Tuple{Any, Any}","page":"API","title":"DiskJockey.model.generate_vel_mask","text":"Generate a boolean mask corresponding to the velocities which fall inside the user-specified mask ranges. arr is an array of [start, end] pairs, like arr = [[1.0, 3.0], [4.0, 5.2]] vels are the velocities corresponding to the dataset, like vels = [1.2, 2.4, 3.6], etc.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.model.lnprior_base-Tuple{DiskJockey.model.AbstractParameters}","page":"API","title":"DiskJockey.model.lnprior_base","text":"The common sense priors that apply to all parameter values\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.model.write_grid-Tuple{AbstractString, DiskJockey.model.Grid}","page":"API","title":"DiskJockey.model.write_grid","text":"This function only needs to be run once, upon setup.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.model.write_lambda-Tuple{AbstractArray, AbstractString}","page":"API","title":"DiskJockey.model.write_lambda","text":"Write the wavelength sampling file. Only run on setup\n\n\n\n\n\n","category":"method"},{"location":"api.html#image.jl","page":"API","title":"image.jl","text":"","category":"section"},{"location":"api.html","page":"API","title":"API","text":"Modules = [image]","category":"page"},{"location":"api.html#DiskJockey.image","page":"API","title":"DiskJockey.image","text":"The image module contains various data types for reading and holding images produced by the radiative transfer programs (via RADMC-3D), as well as routines for processing these images.\n\n\n\n\n\n","category":"module"},{"location":"api.html#DiskJockey.image.RawImage","page":"API","title":"DiskJockey.image.RawImage","text":"RawImage(data, pixsize_x, pixsize_y, lams)\n\nHold the raw output from RADMC-3D in a 3D array (npixy, npixx, nlam). RawImage reflects the RADMC convention that both x and y are increasing with array index. This means that to display the image as RADMC intends it, you must set the first array element to the lower left corner.\n\n\n\n\n\n","category":"type"},{"location":"api.html#DiskJockey.image.SkyImage","page":"API","title":"DiskJockey.image.SkyImage","text":"SkyImage is a holder that has both RA and DEC increasing with array index This convention is necessary for the FFT step However, to display this image in the traditional sky convention (North up, East to the left), you must set the first array element to the lower left corner and flip the array along the RA axis: fliplr(data) or flipdim(data, 2)\n\n\n\n\n\n","category":"type"},{"location":"api.html#DiskJockey.image.SkyImage-Tuple{Matrix{Float64}, Vector{Float64}, Vector{Float64}, Float64}","page":"API","title":"DiskJockey.image.SkyImage","text":"SkyImage constructor for just a single frame\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.image.TausurfImg","page":"API","title":"DiskJockey.image.TausurfImg","text":"TausurfImage is designed to hold the results of the RADMC-3D tausurf operation. This is The distance in cm above or below the plane tangent to the observer, which intersects the origin of the model.\n\nFrom the RADMC3D manual: The image output file image.out will now contain, for each pixel, the position along the ray in centimeters where τ = τs. The zero point is the surface perpendicular to the direction of observation, going through the pointing position (which is, by default the origin (0, 0, 0)). Positive values mean that the surface is closer to the observer than the plane, while negative values mean that the surface is behind the plane. So for this datastructure, it's the same thing as RawImage, just instead of intensity, we have distance above/below plane.\n\n\n\n\n\n","category":"type"},{"location":"api.html#DiskJockey.image.TausurfPos","page":"API","title":"DiskJockey.image.TausurfPos","text":"Encapsulates the 3D position of the pixels representing the tau=1 surface, in the same datashape as the image. For each pixel, this is the x, y, or z position.\n\n\n\n\n\n","category":"type"},{"location":"api.html#DiskJockey.image.ZerothMoment","page":"API","title":"DiskJockey.image.ZerothMoment","text":"Storage for zeroth moment map\n\n\n\n\n\n","category":"type"},{"location":"api.html#Base.:--Tuple{DiskJockey.image.SkyImage, DiskJockey.image.SkyImage}","page":"API","title":"Base.:-","text":"Subtraction for SkyImages\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.image.convert-Tuple{Type{DiskJockey.image.ZerothMoment}, DiskJockey.image.SkyImage}","page":"API","title":"DiskJockey.image.convert","text":"convert(::Type{ZerothMoment}, img::SkyImage)\n\nConvert a SkyImage to a ZerothMoment map.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.image.imToSky-Tuple{DiskJockey.image.RawImage, Float64}","page":"API","title":"DiskJockey.image.imToSky","text":"imToSky(img::RawImage, dpc::Float64)\n\nConvert a RawImage to a SkyImage. Assumes dpc is parsecs.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.image.imToSpec-Tuple{DiskJockey.image.SkyImage}","page":"API","title":"DiskJockey.image.imToSpec","text":"Take an image and integrate all the frames to create a spatially-integrated spectrum\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.image.imread","page":"API","title":"DiskJockey.image.imread","text":"imread(file=\"image.out\")\n\nRead the image file (default=image.out) and return it as an Image object, which contains the fluxes in Jy/pixel, the sizes and locations of the pixels in arcseconds, and the wavelengths (in microns) corresponding to the images\n\n\n\n\n\n","category":"function"},{"location":"api.html#DiskJockey.image.integrateSpec-Tuple{Matrix{Float64}, Float64}","page":"API","title":"DiskJockey.image.integrateSpec","text":"Calculate the integrated line flux\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.image.taureadImg","page":"API","title":"DiskJockey.image.taureadImg","text":"taureadImg(file=\"image_tausurf.out\")\n\nLike imread, but for tausurf. Pixels that have no tau surface are set to NaN.\n\n\n\n\n\n","category":"function"},{"location":"api.html#DiskJockey.image.taureadPos","page":"API","title":"DiskJockey.image.taureadPos","text":"Read the (x,y,z) positions of the tau=1 pixels.\n\n\n\n\n\n","category":"function"},{"location":"api.html#visibilities.jl","page":"API","title":"visibilities.jl","text":"","category":"section"},{"location":"api.html","page":"API","title":"API","text":"Modules = [visibilities]","category":"page"},{"location":"api.html#DiskJockey.visibilities.DataVis","page":"API","title":"DiskJockey.visibilities.DataVis","text":"DataVis(fname::AbstractString, index::Int, flagged::Bool=false)\n\nRead just one channel of visibilities from the HDF5 file.\n\n\n\n\n\n","category":"type"},{"location":"api.html#DiskJockey.visibilities.DataVis-2","page":"API","title":"DiskJockey.visibilities.DataVis","text":"DataVis(fname::AbstractString, mask::BitArray, flagged::Bool=false)\n\nRead just a subset of channels from the HDF5 file and return an array of DataVis.\n\n\n\n\n\n","category":"type"},{"location":"api.html#DiskJockey.visibilities.DataVis-3","page":"API","title":"DiskJockey.visibilities.DataVis","text":"DataVis(fname::AbstractString, indices::Vector{Int}, flagged::Bool=false)\n\nRead just a subset of channels from the HDF5 file and return an array of DataVis.\n\n\n\n\n\n","category":"type"},{"location":"api.html#DiskJockey.visibilities.DataVis-4","page":"API","title":"DiskJockey.visibilities.DataVis","text":"DataVis(fname::AbstractString, flagged::Bool=false)\n\nRead all the visibilities from an HDF5 string and return them as an array of DataVis objects flagged means whether we should be loading the flagged points or not.\n\n\n\n\n\n","category":"type"},{"location":"api.html#DiskJockey.visibilities.DataVisReal-Tuple{DiskJockey.visibilities.DataVis}","page":"API","title":"DiskJockey.visibilities.DataVisReal","text":"DataVisReal(dvis::DataVis)\n\nConvert a DataVis object, with visibilities stored as Comlpex128, into an object with visibilities stored with real and complex values stored separately as Float64.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.visibilities.ModelVis-Tuple{DiskJockey.visibilities.DataVis, DiskJockey.visibilities.FullModelVis}","page":"API","title":"DiskJockey.visibilities.ModelVis","text":"ModelVis(dvis::DataVis, fmvis::FullModelVis)\n\nGiven a DataSet and a FullModelVis, go through and interpolate at the u,v locations of the DataVis.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.visibilities.ModelVisReal-Tuple{DiskJockey.visibilities.ModelVis}","page":"API","title":"DiskJockey.visibilities.ModelVisReal","text":"ModelVisReal(mvis::ModelVis)\n\nConvert a ModelVis object, with visibilities stored as ComplexF64, into a ModelVisReal, with real and imaginary visibility values stored separately as Float64.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.visibilities.RawModelVis","page":"API","title":"DiskJockey.visibilities.RawModelVis","text":"RawModelVis\n\nType to store the product of FFT'ing a single channel of a SkyImage.\n\n\n\n\n\n","category":"type"},{"location":"api.html#Base.:--Tuple{DiskJockey.visibilities.FullModelVis, DiskJockey.visibilities.FullModelVis}","page":"API","title":"Base.:-","text":"-(vis1::FullModelVis, vis2::FullModelVis)\n\nSubtract two FullModelVis's.\n\n\n\n\n\n","category":"method"},{"location":"api.html#Base.conj!-Tuple{DiskJockey.visibilities.DataVis}","page":"API","title":"Base.conj!","text":"conj!(dv::DataVis)\n\nImport the complex conjugate function from Base, and extend it to work on a DataVis. I think this is necessary because the SMA and ALMA baseline conventions are swapped from what I'm using in the NRAO Synthesis Summer School textbook.\n\n\n\n\n\n","category":"method"},{"location":"api.html#Base.conj!-Tuple{Vector{DiskJockey.visibilities.DataVis}}","page":"API","title":"Base.conj!","text":"conj!(dvarr::Array{DataVis, 1})\n\nApply conj to an entire DataVis array.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.visibilities.ModelVis2DataVis-Tuple{DiskJockey.visibilities.ModelVis}","page":"API","title":"DiskJockey.visibilities.ModelVis2DataVis","text":"ModelVis2DataVis(mvis::ModelVis)\n\nCollapse a ModelVis into a DataVis in order to write to disk.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.visibilities.ModelVisRotate-Tuple{DiskJockey.visibilities.DataVis, DiskJockey.visibilities.FullModelVis, Real}","page":"API","title":"DiskJockey.visibilities.ModelVisRotate","text":"ModelVisRotate(dvis::DataVis, fmvis::FullModelVis, PA::Real)\n\nGiven a DataSet, FullModelVis, and a desired position angle rotation, use the Fourier rotation theorem to sample the image at the rotated baselines and produce a rotated (sampled) model. A positive PA value (in degrees) means that the new model is rotated PA number of degrees counter-clockwise in the image plane (towards East, from North).\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.visibilities.ResidVis-Tuple{Vector{DiskJockey.visibilities.DataVis}, Any}","page":"API","title":"DiskJockey.visibilities.ResidVis","text":"ResidVis(dvarr::Array{DataVis, 1}, mvarr)\n\nReturn a model visibility file that contains the residuals.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.visibilities.chi2-Tuple{DiskJockey.visibilities.DataVis, DiskJockey.visibilities.ModelVis}","page":"API","title":"DiskJockey.visibilities.chi2","text":"chi2(dvis::DataVis, mvis::ModelVis)\n\nCalculate the chi^2 value of the current model. This function is not used in inference (see lnprob), but it is sometimes a useful number to report.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.visibilities.copy_flags-Tuple{AbstractString, AbstractString}","page":"API","title":"DiskJockey.visibilities.copy_flags","text":"copy_flags(source::AbstractString, dest::AbstractString)\n\nCopy the flags from one dataset to another.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.visibilities.fftfreq-Tuple{Int64, Float64}","page":"API","title":"DiskJockey.visibilities.fftfreq","text":"fftfreq(n::Int, d::Float64)\n\nAfter numpy.fft.fftfreq\n\nf = [0, 1, ...,   n/2-1,     -n/2, ..., -1] / (d*n)   if n is even\nf = [0, 1, ..., (n-1)/2, -(n-1)/2, ..., -1] / (d*n)   if n is odd.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.visibilities.fillModelVis-Tuple{DiskJockey.visibilities.RawModelVis}","page":"API","title":"DiskJockey.visibilities.fillModelVis","text":"fillModelVis(vis::RawModelVis)\n\nThis function is designed to copy the partial arrays in RawModelVis into a full image for easy plotting. This means that the u axis can remain the same but we'll need to make the complex conjugate of the v axis.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.visibilities.get_nyquist_pixel-Tuple{Float64, Float64}","page":"API","title":"DiskJockey.visibilities.get_nyquist_pixel","text":"get_nyquist_pixel(max_base::Float64, angular_width::Float64)\n\nDetermine how many pixels the image needs at a given distance in order to satisfy the Nyquist sampling theorem.\n\nmax_base is in kilolambda. angular_width is in radians.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.visibilities.get_qq-Tuple{DiskJockey.visibilities.DataVis}","page":"API","title":"DiskJockey.visibilities.get_qq","text":"get_qq(dv::DataVis)\n\nGiven a DataVis, convert the Cartesian spatial frequency coordinates (uv) into a radial spatial coordinate q.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.visibilities.interpolate_uv-Tuple{Float64, Float64, DiskJockey.visibilities.FullModelVis}","page":"API","title":"DiskJockey.visibilities.interpolate_uv","text":"interpolate_uv(u::Float64, v::Float64, vis::FullModelVis)\n\nInterpolates a dense grid of visibilities (e.g., from FFT of an image) to a specfic (u,v) point using spheroidal functions in a band-limited manner designed to reduce aliasing.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.visibilities.lnprob-Tuple{DiskJockey.visibilities.DataVis, DiskJockey.visibilities.DataVis}","page":"API","title":"DiskJockey.visibilities.lnprob","text":"lnprob(dvis::DataVis, mvis::DataVis)\n\nLnprob for computing the difference between two datasets. Does not check whether the baselines of the two datasets are the same. Use this function at your own discretion.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.visibilities.lnprob-Tuple{DiskJockey.visibilities.DataVis, DiskJockey.visibilities.ModelVis, Float64, Float64}","page":"API","title":"DiskJockey.visibilities.lnprob","text":"lnprob(dvis::DataVis, mvis::ModelVis, mu_RA::Real, mu_DEC::Real)\n\nCalculate the lnlikelihood using a single loop to do the phase shifting and summation. No extra memory needed for re-copying the model.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.visibilities.lnprob-Tuple{DiskJockey.visibilities.DataVis, DiskJockey.visibilities.ModelVis}","page":"API","title":"DiskJockey.visibilities.lnprob","text":"lnprob(dvis::DataVis, mvis::ModelVis)\n\nLikelihood function used to calculate the likelihood of the data visibilities given a current model of them. Asserts that the model visibilities were sampled at the same baselines as the data.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.visibilities.lnprob_real-Tuple{DiskJockey.visibilities.DataVisReal, DiskJockey.visibilities.ModelVisReal, Any}","page":"API","title":"DiskJockey.visibilities.lnprob_real","text":"lnprob_real(dvis::DataVis, mvis::ModelVis, mu_RA::Float64, mu_DEC::Float64)\n\nCalculate the lnlikelihood using a single loop to do the phase shifting and summation. No extra memory needed for re-copying the model. Uses Euler formula to do the calculation, rather than exponentiating a complex number.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.visibilities.max_baseline-Tuple{Vector{DiskJockey.visibilities.DataVis}}","page":"API","title":"DiskJockey.visibilities.max_baseline","text":"max_baseline(dvarr)\n\nDetermine the maximum uu or vv baseline contained in the dataset, so we know at what resolution we will need to synthesize the images.\n\nreturned in kilolambda.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.visibilities.phase_shift!-Tuple{DiskJockey.visibilities.FullModelVis, Any, Any}","page":"API","title":"DiskJockey.visibilities.phase_shift!","text":"phase_shift!(fvis::FullModelVis, mu_RA, mu_DEC)\n\nGiven a new model centroid in the image plane (in arcseconds), shift the model visibilities by corresponding amount.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.visibilities.phase_shift!-Tuple{DiskJockey.visibilities.ModelVis, Any, Any}","page":"API","title":"DiskJockey.visibilities.phase_shift!","text":"phase_shift!(mvis::ModelVis, mu_RA, mu_DEC)\n\nGiven a new model centroid in the image plane (in arcseconds), shift the model visibilities by corresponding amount.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.visibilities.plan_interpolate-Tuple{DiskJockey.visibilities.DataVis, Vector{Float64}, Vector{Float64}}","page":"API","title":"DiskJockey.visibilities.plan_interpolate","text":"plan_interpolate(dvis::DataVis, uu::Vector{Float64}, vv::Vector{Float64})\n\nReturn a function that is used to interpolate the visibilities, in the spirit of interpolate_uv but much faster. Closures save time and money!\n\nThe uu and vv vectors are the visibility coordinates for the dense visibility model.\n\nThe point is that if the distance to the source and the size of the sythesized image are not changing, then we will always be interpolating from a dense Visibility grid that has the exact same U and V spacings, meaning that the weighting terms used to evaluate the interpolation for a specific visibility can be cached.\n\nSo, using a closure, those weighting terms are calculated once and then cached for further use.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.visibilities.rfftfreq-Tuple{Int64, Float64}","page":"API","title":"DiskJockey.visibilities.rfftfreq","text":"rfftfreq(n::Int, d::Float64)\n\nReturn the frequencies corresponding to the output of the real FFT. After numpy.fft.rfftfreq     f = [0, 1, ...,     n/2-1,     n/2] / (dn)   if n is even     f = [0, 1, ..., (n-1)/2-1, (n-1)/2] / (dn)   if n is odd.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.visibilities.transform","page":"API","title":"DiskJockey.visibilities.transform","text":"transform(img::SkyImage, index::Int=1)\n\nTransform the SkyImage produced by RADMC using FFT.\n\n\n\n\n\n","category":"function"},{"location":"api.html#DiskJockey.visibilities.write-Tuple{DiskJockey.visibilities.DataVis, AbstractString}","page":"API","title":"DiskJockey.visibilities.write","text":"write(dv::DataVis, fname::AbstractString)\n\nTake in a visibility data set and then write it to the HDF5 file The HDF5 file actually expects multi-channel data, so instead we will need to store all of this information with arrays of shape (..., 1) [an extra trailing] dimension of 1.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.visibilities.write-Tuple{Vector{DiskJockey.visibilities.DataVis}, AbstractString}","page":"API","title":"DiskJockey.visibilities.write","text":"write(dvarr::Array{DataVis, 1}, fname::AbstractString)\n\nWrite an array of DataVis to a single HDF5 file.\n\n\n\n\n\n","category":"method"},{"location":"api.html#gridding.jl","page":"API","title":"gridding.jl","text":"","category":"section"},{"location":"api.html","page":"API","title":"API","text":"Modules = [gridding]","category":"page"},{"location":"api.html#DiskJockey.gridding.corrfun!-Tuple{DiskJockey.image.SkyImage, Any, Any}","page":"API","title":"DiskJockey.gridding.corrfun!","text":"corrfun!(img::SkyImage, mu_RA, mu_DEC)\n\nApply the correction function to the SkyImage, with an offset in RA and DEC.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.gridding.corrfun!-Tuple{DiskJockey.image.SkyImage}","page":"API","title":"DiskJockey.gridding.corrfun!","text":"corrfun!(img::SkyImage)\n\nApply the correction function to (and mutate) a SkyImage in place.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.gridding.corrfun-Tuple{DiskJockey.image.SkyImage}","page":"API","title":"DiskJockey.gridding.corrfun","text":"corrfun(img::SkyImage)\n\nApply the correction function to a SkyImage, but return a copy of the image, leaving the original unchanged.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.gridding.corrfun-Tuple{T} where T","page":"API","title":"DiskJockey.gridding.corrfun","text":"corrfun(eta::T) where {T}\n\nGridding correction function, but able to be passed either floating point numbers or vectors of Float64.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.gridding.corrfun-Union{Tuple{T}, Tuple{T, Float64}} where T","page":"API","title":"DiskJockey.gridding.corrfun","text":"corrfun(eta::T, alpha::Float64) where {T}\n\nGridding correction function, used to pre-divide the image to correct for the effect of the gcffun. This function is also the Fourier transform of gcffun.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.gridding.gcffun-Tuple{T} where T","page":"API","title":"DiskJockey.gridding.gcffun","text":"gcffun(eta::T) where {T}\n\nThe gridding convolution function, used to do the convolution and interpolation of the visibilities in the Fourier domain. This is also the Fourier transform of corrfun.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.gridding.gcffun-Union{Tuple{T}, Tuple{T, Float64}} where T","page":"API","title":"DiskJockey.gridding.gcffun","text":"gcffun(eta::T, alpha::Float64) where {T}\n\nThe gridding convolution function, with variable alpha.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.gridding.spheroid-Tuple{Float64, Float64}","page":"API","title":"DiskJockey.gridding.spheroid","text":"spheroid(eta, alpha)\n\nProlate spheroidal wavefunction, assuming that m = 6. This allows arguments for eta  10 + 10^-7, but returns 0.0 (i.e., the spheroid window is truncated).\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.gridding.spheroid-Tuple{Float64}","page":"API","title":"DiskJockey.gridding.spheroid","text":"spheroid(eta)\n\nspheroid function which assumes alpha = 1.0, m=6, built for speed.\n\n\n\n\n\n","category":"method"},{"location":"api.html#gauss.jl","page":"API","title":"gauss.jl","text":"","category":"section"},{"location":"api.html","page":"API","title":"API","text":"Modules = [gauss]","category":"page"},{"location":"api.html#DiskJockey.gauss","page":"API","title":"DiskJockey.gauss","text":"Provide routines for making fake Gaussian models which have analytic Fourier transforms, for the purposes of testing.\n\n\n\n\n\n","category":"module"},{"location":"api.html#DiskJockey.gauss.FTGauss-Tuple{AbstractVector{Float64}, AbstractVector{Float64}, Vector{Float64}, Real}","page":"API","title":"DiskJockey.gauss.FTGauss","text":"FTGauss(uu::AbstractVector{Float64}, vv::AbstractVector{Float64}, p::Vector{Float64}, k::Int)\n\np is a length 5 vector of mu_RA, mu_DEC, sigma_RA, sigma_DEC, rho.\n\nGiven two arrays of u and v coordinates in [kλ], fill an array with the analytic FT of imageGauss evaluated at every pairwise (u,v) pair.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.gauss.FTGauss-Tuple{Float64, Float64, Vector{Float64}, Real}","page":"API","title":"DiskJockey.gauss.FTGauss","text":"FTGauss(uu::Float64, vv::Float64, p::Vector{Float64}, k::Real)\n\nGiven u and v coordinates in [kλ], evaluate the analytic FT of the aforementioned Gaussian.\n\np is a length 5 vector of [mu_RA, mu_DEC, sigma_x, sigma_y, rho] in units of arcseconds, corresponding to the image plane.\n\nN.B. Here Sigma refers to the (same) covariance matrix in the image domain.\n\nThis function always returns a complex value.\n\n\n\n\n\n","category":"method"},{"location":"api.html#DiskJockey.gauss.imageGauss-Tuple{AbstractVector{Float64}, AbstractVector{Float64}, Vector{Float64}, Real}","page":"API","title":"DiskJockey.gauss.imageGauss","text":"imageGauss(ll::AbstractVector{Float64}, mm::AbstractVector{Float64}, p::Vector{Float64}, k::Real; theta=0)\n\nGiven two arrays of l and m coordinates, corresponding to x and y, fill an array of the Gaussian image following the MATLAB convention for images (each row corresponds to a different y value).\n\np0 is a vector of [mu_RA, mu_DEC, sigma_x, sigma_y, rho] in units of arcseconds. rho is the correlation of the Gaussian, ranging from 0 to 1.\n\nrho = fracsigma_xysigma_x sigma_y\n\nmu_alpha and mu_delta are the locations of the centroid emission relative to the image origin (RA=0, DEC=0).\n\nk is a scaling pre-factor to adjust the amplitude of the Gaussian.\n\nThe image intensity as a function of l and m (sky plane coordinates) is\n\n    I(lm) = frack2 pi sqrtboldsymbolSigma exp left  -frac12 boldsymbolR^mathrmT boldsymbolSigma^-1 boldsymbolR right \n\nWhere boldsymbolSigma is\n\nboldsymbolSigma = left  beginarraycc\nsigma_x  sigma_xy \nsigma_xy  sigma_y \nendarray right \n\ntheta is a desired angle to rotate the Gaussian about the origin. To make sense of the order of operations, the rotation must occur about the origin. A positive value means a counter-clockwise rotation of the Gaussian from North towards East.\n\n\n\n\n\n","category":"method"},{"location":"api.html#EnsembleSampler.jl","page":"API","title":"EnsembleSampler.jl","text":"","category":"section"},{"location":"api.html","page":"API","title":"API","text":"This is a Julia port of the Python package emcee, written by Dan Foreman-Mackey and collaborators.","category":"page"},{"location":"api.html","page":"API","title":"API","text":"Modules = [EnsembleSampler]","category":"page"},{"location":"api.html#Index","page":"API","title":"Index","text":"","category":"section"},{"location":"api.html","page":"API","title":"API","text":"","category":"page"},{"location":"conventions.html#Conventions","page":"Conventions","title":"Conventions","text":"","category":"section"},{"location":"conventions.html#Inclination","page":"Conventions","title":"Inclination","text":"","category":"section"},{"location":"conventions.html","page":"Conventions","title":"Conventions","text":"Disk inclination ranges from 0 to 180 degrees. 0 degrees means face on, angular momentum vector pointing at observer; 90 means edge on; and 180 means face on, angular momentum vector pointing away from observer. These are the same as the RADMC-3D conventions and the typical conventions in the astrometric orbital field: inclination < 90 means counter-clockwise rotation and inclination > 90 means clockwise rotation.","category":"page"},{"location":"conventions.html#Position-Angle","page":"Conventions","title":"Position Angle","text":"","category":"section"},{"location":"conventions.html","page":"Conventions","title":"Conventions","text":"We adopt the RADMC-3D convention for position angle, which defines position angle by the angular momentum vector. A positive PA angle means the disk angular momentum vector will be rotated counter clockwise (from North towards East). ","category":"page"},{"location":"conventions.html","page":"Conventions","title":"Conventions","text":"The convention used by DiskJockey and RADMC-3D is 90 degrees offset from the convention frequently used in the orbital field, which defines position angle using the ascending node, Omega. For disks, the ascending node is the redshifted portion of the disk major axis (see Czekala et al. 2019 for a discussion).","category":"page"},{"location":"cookbook.html#Cookbook","page":"Cookbook","title":"Cookbook","text":"","category":"section"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"After you have installed DiskJockey, it's time to get up and running!","category":"page"},{"location":"cookbook.html#Initialization","page":"Cookbook","title":"Initialization","text":"","category":"section"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"Now the DiskJockey package should be successfully installed user-wide. Because it is likely that you will want to fit more than just one protoplanetary disk, or perhaps try different model specifications for a particular disk, the code structure is organized so that you will have a separate directory for each disk model. The following is an example to get you started fitting AK Sco.","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"$ mkdir AKSco\n$ cd AKSco","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"Make sure to download the dataset in HDF5 format here.","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"Now, you'll want to initialize this directory with a config file. This config file will store all of the options that are specific to fitting this disk and is frequently used by many of the scripts in this package. To initialize,","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"$ DJ_initialize.jl --new-project=standard\nCopied default config.yaml, InitializeWalkers.ipynb, and Makefile for the standard model to current working directory.\nExiting","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"--new-project also has other than standard, such as cavity and vertical in order to fit more exotic models. Now, open up config.yaml with your favorite text editor and change the fields as you see fit, including which transition of CO you would like to fit. Currently (v0.1.3), this package only includes functionality for 12CO, 13CO, and C18O in LTE. Please create an issue on the github repository if you would like a new species added.","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"To help get you started, here are some reasonable fields for the config.yaml file for AK Sco:","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"General synthesis parameters:","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"name: AKSco\ngas: true\nspecies : 12CO # Possible choices: 12CO, 13CO, C18O. Future may include HCN, etc...\ntransition: 2-1 # J =","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"The model grid setup:","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"grid:\n  nr: 128\n  ntheta: 40 # if mirrored about the equator, total of 80\n  nphi: 1\n  r_in: 0.1 # [AU] # Inner edge of model grid\n  r_out: 300. # [AU] # Outer edge of model grid","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"The distance parameters. For now, we will keep distance fixed:","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"fix_params : [\"dpc\"]","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"Even though we are keeping the distance fixed, we need to specify these prior parameters:","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"dpc_prior:\n\tmu: 142.\n\tsig: 20.","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"Choose what type of model will we be fitting:","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"model : standard # choices of {standard, truncated, vertical, cavity, etc..}","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"Now come parameters that can be used to synthesize and plot models. Due to a quirk of how YAML files are read, make sure that each of these parameter values is a float and not an int (i.e., 1.0 vs. 1).","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"parameters:\n  M_star: 2.49 # [M_sun] stellar mass\n  r_c: 14.00 # [AU] characteristic radius\n  T_10: 91.85 # [K] temperature at 10 AU\n  q: 0.51 # temperature gradient exponent\n  gamma: 1.0 # surface density gradient\n  logSigma_c: 3.0 # log surface density at char. radius\n  ksi: 0.31 # [km/s] microturbulence\n  dpc: 142. # [pc] distance\n  incl: 109.4 # [degrees] inclination\n  PA: 141.1 # [degrees] position angle\n  vel: -26.1 # [km/s]\n  mu_RA: 0.053 # [arcsec] centroid location\n  mu_DEC: 0.045 # [arcsec]","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"Of all of these parameters, it might be hardest to guess correctly at the systemic velocity of the source. Generally, this is best done in the data reduction stages, for example taking a quick look at the central frequency of the spectral line. Note that the AK Sco dataset is provided in the raw topocentric frame, so the velocity quoted here is not the same as the LSRK quoted in the paper.","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"Now, we need to specify how big we want our image to be and how many pixels it should have.","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"# Image setup\nsize_arcsec : 12.0 # [arcsec] full width/height of image\nnpix: 512","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"The final section is parameters that roughly describe the RMS in the observation and the approximate beam size. These parameters are only used in the channel map plotting script to help make the channel maps look more comparable to the observation, and you don't need to worry about them now.","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"beam :\n  rms : 0.01 # Jy/beam\n  BMAJ: 0.9 # arcsec # Major axis of ellipse\n  BMIN: 0.9 # arcsec # Minor axis of ellipse\n  BPA: 1.0 # degrees east of North of the semi-major axis.","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"Now, a good thing to check is that our setup parameters actually satisfy the Nyquist theorem. There is a helper script for this","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"$ max_baseline.jl\nDataset channels are velocities from -10.517295788189767 to -42.656605289812504 and span -32.13930950162273 km/s.\nMidpoint is -26.586950539001137 km/s.\nMax baseline 338.5121039138373 kilolambda\nNyquist sampling satisfied. dRA: 0.0234375 [arcsec/pix] ; dRA_max: 0.2769671424693894 [arcsec/pix]\nImage size satisfied. Image size at the closest distances: 510.0 [AU]; outer radius of the grid + 10%: 330.0 [AU]","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"It looks like everything is OK to start!  (If you see very different velocities here for the channels, check that you have correctly specified species and transition in config.yaml to match the spectral line actually observed in your dataset.) ","category":"page"},{"location":"cookbook.html#Makefile","page":"Cookbook","title":"Makefile","text":"","category":"section"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"New in v0.1.3, I've written a Makefile which should simplify a lot of the necessary tasks within the directory for a single object. You can generally do everything you need to via make <target>, where the various targets will now be described.","category":"page"},{"location":"cookbook.html#Plotting-up-the-model-structure","page":"Cookbook","title":"Plotting up the model structure","text":"","category":"section"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"To get a first pass glimpse at what the model will look like, you can make plots of the key quantities as a function of disk position.","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"$ make structure","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"will create plots in your current working directory of velocity, temperature, and surface density. If want to play around with this, change a parameter in config.yaml and then rerun make structure","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"(Image: Temperature)","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"(Image: Surface Density)","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"(Image: Velocity)","category":"page"},{"location":"cookbook.html#Synthesizing-a-model-image","page":"Cookbook","title":"Synthesizing a model image","text":"","category":"section"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"Before jumping into running any MCMC chains, it is a good idea to take a guess at some parameters and try synthesizing a set of model channel maps to see if your model looks remotely close to the dataset. Then, you can play around with values in config.yaml to see what works well.","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"To jump right in, just try","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"$ make chmaps","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"And the code will start synthesizing channel maps. Because the AK Sco dataset contains a lot of channels, this may take about 5 minutes to get everything done. During this process, the output from RADMC-3D is piped to STDOUT. This may be a good place to debug if anything looks fishy.","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"When complete, this should leave you with several chmaps_*.png files in your current directory. Take a look and see if these appear reasonable.","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"For me, a typical workflow for playing around with channel maps is","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"edit config.yaml to parameters that might make sense\nrun make structure to see that the disk properties look reasonable\nrun make chmaps to actually synthesize images\ninspect the resulting plots of the data (chmaps_linear.png), and if I am not satisfied go back to 1","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"It is a very good idea to inspect your channel maps to make sure that there isn't any weird structure, that you have enough pixels to resolve the disk structure, and that your model grid appears to be at high enough resolution. A few extra minutes or hours spent debugging your images during this step can save you days (of supercomputer time) in the steps ahead.","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"(Image: High Resolution Image of AK Sco)","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"If you'd like to make a spatially-integrated spectrum, you can also do","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"$ make spectrum.png","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"(Image: Spectrum of AK Sco)","category":"page"},{"location":"cookbook.html#Setting-up-a-parallelized-MCMC-exploration-of-the-parameters","page":"Cookbook","title":"Setting up a parallelized MCMC exploration of the parameters","text":"","category":"section"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"As you just experienced, model synthesis can take a very long time, generally 1 - 5 minutes per model in the case of AK Sco. In order to explore the posterior in a reasonable amount of time, we need to parallelize the synthesis and evaluation of the likelihood function across multiple compute cores. This is done using a Julia port of the Ensemble Sampler by Goodman and Weare 2010, implemented in Python by Foreman-Mackey et al. as emcee. For more information about this great sampler, see here.","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"Much like emcee, starting out requires deciding upon the positions of the walkers. To aid in placing these, the DJ_initialize.jl script copied over a Jupyter/Python notebook to your current directory. Now, open up InitializeWalkers.ipynb with a Jupyter notebook. We will change these following values to correspond to your disk of choice.","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"To save you some computational time otherwise spent on burn-in, I found that the following walker starting positions worked well for AK Sco","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"p0 = np.array([np.random.uniform(2.4, 2.5, nwalkers), # mass [M_sun]\n          np.random.uniform(14., 15.0, nwalkers), #r_c [AU]\n          np.random.uniform(92., 93., nwalkers), #T_10 [K]\n          np.random.uniform(0.51, 0.55, nwalkers), # q\n          np.random.uniform(-3.5, -3.4, nwalkers), #log10 M_gas [log10 M_sun]\n          np.random.uniform(0.3, 0.32, nwalkers), #xi [km/s]\n          np.random.uniform(140.0, 144.0, nwalkers), #dpc [pc]\n          np.random.uniform(110.0, 112.0, nwalkers), #inc [degrees]\n          np.random.uniform(140.0, 141.0, nwalkers), #PA [degrees]\n          np.random.uniform(-26.1, -26.0, nwalkers), #vz [km/s]\n          np.random.uniform(0.0, 0.05, nwalkers), #mu_a [arcsec]\n          np.random.uniform(0.0, 0.4, nwalkers)]) #mu_d [arcsec]","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"Then finish evaluating the rest of the cells so that you save the file pos0.npy into your current working directory.","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"How many walkers should you use? Due the the way the Ensemble Sampler advances, you can only evaluate half of the walkers simultaneously. That means that if you are running with more cores than nwalkers/2, you will have several cores idle throughout the sampling. Of course, you could now increase the number of walkers to be 2 * ncores.","category":"page"},{"location":"cookbook.html#Launching-the-run","page":"Cookbook","title":"Launching the run","text":"","category":"section"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"The exploration of the posterior is done via the scripts/venus.jl script. It is worth exploring this piece of code to see the various moving parts. How you invoke this script depends on your cluster environment. For a dataset the size of AK Sco, it's not worth your time to start run this script (except for debugging purposes) unless you have access to 20 or more cores.","category":"page"},{"location":"cookbook.html#Local-machine-with-20-cores","page":"Cookbook","title":"Local machine with 20 cores","text":"","category":"section"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"If you have your own 20-core machine, you can launch the script via  ","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"$ venus.jl -p 19","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"Much like the Julia interpreter itself, the -p argument will add an addition 19 workers to the master process for a total of 20 workers.","category":"page"},{"location":"cookbook.html#High-Performance-Cluster","page":"Cookbook","title":"High Performance Cluster","text":"","category":"section"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"These Julia scripts can take advantage many possible cores spread across multiple nodes. This may require some custom script writing for your specific cluster situation, but the main ideas are as follows","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"write a submission script that specifies total number of cores, time, memory, etc\nupon submission, determine how many cores you have been allocated on which nodes\ncreate a hosts.txt file which contains this information, following the Julia spec here.\nthen start your job with\njulia –machinefile hosts.txt venus.jl","category":"page"},{"location":"cookbook.html#Examining-the-output","page":"Cookbook","title":"Examining the output","text":"","category":"section"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"Because the MCMC run is so expensive, the code is designed to periodically write out snapshots of the samples, to both save your progress and allow you to check up on the chains mid-run. You can set the cadence in the config.yaml file under","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"# MCMC setup\nsamples: 10\nloops: 1","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"Basically, in each loop, the code advances N samples. After each loop, the full chain (chain.npy) is written to the output/ directory along with a current snapshot of the walker positions, pos0.npy. This way if your venus.jl script ends (either by design or cluster failure), you can copy this pos0.npy back to your project directory and start from the last known walker positions.","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"At this point you can take the samples in chain.npy and analyze them as you would normal MCMC samples. To save you the trouble, however, we included a script to help with these tasks","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"$ plot_walkers.py","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"will plot the walker positions as a function of iteration (walkers.png). Examining walkers.png is a decent way to estimate if your chains are done with burn-in.","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"When you are ready, you can burn off these first say 300 (or more) iterations and make a corner plot (triangle.png) by","category":"page"},{"location":"cookbook.html","page":"Cookbook","title":"Cookbook","text":"$ plot_walkers.py --burn 300 --tri","category":"page"},{"location":"changelog.html#Changelog","page":"Changelog","title":"Changelog","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"The following are the changes that have been implemented since the previous version. All versions are tagged as releases and available as a clone off of the master branch.","category":"page"},{"location":"changelog.html#Version-0.1.6","page":"Changelog","title":"Version 0.1.6","text":"","category":"section"},{"location":"changelog.html#Splitting-package-testing","page":"Changelog","title":"Splitting package testing","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"DiskJockey is a computation and data intensive program. This makes it difficult to functionally test every aspect of the program quickly. To help create a testing funnel from quick, unit tests all the way through to larger integration tests, I've split the tests into two places. Within the main DiskJockey package are those tests that can be done quickly and are limited to testing the code within src/ (i.e., not testing scripts/).","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"The larger integration tests are split out into a different Julia package, DiskJockeyTests.jl that is currently under construction. The idea is that this package will be run in a cluster environment and is designed to run through the loading and analysis of an actual dataset. It is designed to catch the kind of bug that you only discover after queuing for cores for several hours.","category":"page"},{"location":"changelog.html#Github-actions","page":"Changelog","title":"Github actions","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"Continuous Integration testing and documentation builds are now done with Github-actions.","category":"page"},{"location":"changelog.html#Package-environment","page":"Changelog","title":"Package environment","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"Added using Pkg; Pkg.activate(\"DiskJockey\") to all of the scripts. This way, these scripts should use the versions of the packages installed along with the DiskJockey package itself, and you won't need to (re)install these same packages to your local environment.","category":"page"},{"location":"changelog.html#Optimization-routines","page":"Changelog","title":"Optimization routines","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"In addition to the normal MCMC sampling routines, we've included the option to use an optimizer instead, via BlackBoxOptim.jl. This should greatly expedite getting an estimate of the \"best-fit\" model, but won't replace the need to do a full MCMC to get the posterior distributions.","category":"page"},{"location":"changelog.html#Removed-plotly","page":"Changelog","title":"Removed plotly","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"Removed plotly support, since this was just adding bloat.","category":"page"},{"location":"changelog.html#Total-gas-mass-vs.-surface-density-parameterization","page":"Changelog","title":"Total gas mass vs. surface density parameterization","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"The normalization of the disk surface density profile can either be parameterized as a surface density at a given radius (often Sigmac, the surface density at rc) or as the total disk mass. These choices are of course equivalent, but the parameterizations have consequences for how efficiently the posterior can be sampled (Mgas is usually less correlated with other parameters than rc) and how quickly the 3D densities can be computed (rc is quicker than Mgas).","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"To get the best of both worlds, we've added BOTH Sigmac and Mgas to the model types, and added an outer constructer that computes Sigmac from Mgas. From the users perspective, they should only have to interact with Mgas. But, this way the routines in model.jl can also just query Sigmac each time they need it.","category":"page"},{"location":"changelog.html#Version-0.1.5","page":"Changelog","title":"Version 0.1.5","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"Updates to make everything compatible with Julia v1.0. ","category":"page"},{"location":"changelog.html#Version-0.1.4","page":"Changelog","title":"Version 0.1.4","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"Upgraded to Julia version 0.6. To upgrade to this version of DiskJockey, you will first need to upgrade your own Julia distribution to 0.6 as well. I apologize for the frequent upgrades of Julia, but since Julia is itself a fast-developing language, it makes the most sense to just bite the bullet and upgrade every time the programming language upgrades as well. Once Julia reaches v1.0 (sometime in 2018, perhaps), these changes should become less frequent.","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"After you install the new version of Julia, make sure that it actually loads as","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"$ julia\n               _\n   _       _ _(_)_     |  A fresh approach to technical computing\n  (_)     | (_) (_)    |  Documentation: https://docs.julialang.org\n   _ _   _| |_  __ _   |  Type \"?help\" for help.\n  | | | | | | |/ _` |  |\n  | | |_| | | | (_| |  |  Version 0.6.1-pre.92 (2017-10-07 01:18 UTC)\n _/ |\\__'_|_|_|\\__'_|  |  Commit 389b23cf6e* (6 days old release-0.6)\n|__/                   |  x86_64-pc-linux-gnu\n\njulia>","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"And then you will need to reinstall DiskJockey in this new version, which should automatically pull down all of the other packages.","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"julia> Pkg.clone(\"https://github.com/iancze/DiskJockey.git\")","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"If you no longer plan on using Julia v0.4 or v0.5 or any of the packages, I would recommend deleting it from your system so as not to cause any PATH conflicts. Speaking of which, don't forget to update your PATH to point to the new v0.6 version scripts.","category":"page"},{"location":"changelog.html#Updated-RADMC-3D","page":"Changelog","title":"Updated RADMC-3D","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"We're now running the latest version of RADMC-3D (0.41), which is automatically downloaded and installed with DiskJockey. Although not strictly required for running DiskJockey, it might help to familiarize yourself with the RADMC-3D manual, in particular the sections on input files and LTE line transfer.","category":"page"},{"location":"changelog.html#Renaming","page":"Changelog","title":"Renaming","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"The script max_baseline.jl is now DJ_max_baseline.jl. plot_walkers.py is now DJ_plot_walkers.py.","category":"page"},{"location":"changelog.html#DJ*plot*walkers.py","page":"Changelog","title":"DJplotwalkers.py","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"Now has proper labeling for models that fix parameters.","category":"page"},{"location":"changelog.html#DJ*verify*run.jl","page":"Changelog","title":"DJverifyrun.jl","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"A new script for checking that you've specified everything properly before launching a MCMC run. This way you can avoid syntax errors in the config scripts after queuing for a cluster job.","category":"page"},{"location":"changelog.html#NUKER-profile","page":"Changelog","title":"NUKER profile","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"We've implemented the NUKER profile as a model for the surface density distribution. See Tripathi et al. 2017 for more details.","category":"page"},{"location":"changelog.html#Distance","page":"Changelog","title":"Distance","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"We've removed the following fields from configyaml for all models","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"# Distance prior setup\ndpc_prior:\n  mu : 145.\n  sig : 20.","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"The main reason is that because the dynamical mass results are completely degenerate with distance in a linear manner, it doesn't make sense to sample in distance, especially if the prior is a simple analytical form like a Gaussian. This means that the normal mode of operation will be to include dpc in the fix_params field, as is commonly done. If the users require sampling in dpc, then they can remove it from fix_params and write a prior in a custom priorjl file.","category":"page"},{"location":"changelog.html#InitializeWalkers.ipynb-to-initialize_walkers.py","page":"Changelog","title":"InitializeWalkers.ipynb to initialize_walkers.py","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"Rather than editing the walker initialization script with an IPython notebook, instead it is now done with a simple python script. Functionally, these are the same, but the script removes the extra startup time of a Jupyter notebook.","category":"page"},{"location":"changelog.html#Version-0.1.3","page":"Changelog","title":"Version 0.1.3","text":"","category":"section"},{"location":"changelog.html#Fix-parameters","page":"Changelog","title":"Fix parameters","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"Now there is a flexible way to fix or free parameters in a fit.","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"To do this requires new config files (which you may need to copy over from assets/) that include a params_fixed field, where you list the parameters to fix. Then, it may also require modifying the InitializeWalkers.ipynb notebooks to incorporate more or fewer parameters than are currently available.","category":"page"},{"location":"changelog.html#Cavity-model","page":"Changelog","title":"Cavity model","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"Now supports a cavity model, with parameters for the size of the cavity (r_cav), as well as the steepness (gamma_cav).","category":"page"},{"location":"changelog.html#Truncated-model","page":"Changelog","title":"Truncated model","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"Now includes a model that has a variable outer exponential taper, allowing it to be steeper or shallower than the traditional (2 - gamma).","category":"page"},{"location":"changelog.html#Change-to-Sigma_c","page":"Changelog","title":"Change to Sigma_c","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"Instead of fitting with the parameter total gas mass, we now fit with the surface density normalization at the critical radius, Sigma_c. Note that this only truly the normalization constant for the standard, truncated, and vertical models. The reason for the switch from M_gas to Sigma_c is that for more complicated models, there is no analytic formula for the total gas mass, meaning that a numerical integral would be needed for each model evaluation. It is simpler and more accurate to sample in Sigma_c and then later convert the samples to M_gas if desired.","category":"page"},{"location":"changelog.html#FITS-export","page":"Changelog","title":"FITS export","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"Thanks to Jane Huang (@j6626), you can now export a RADMC image to a FITS file via the script DJ_image_to_FITS.py. You can then inspect these FITS files with ds9, or use them in CASA simobserve.","category":"page"},{"location":"changelog.html#spectrum.png","page":"Changelog","title":"spectrum.png","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"The plotting routine now outputs integrated line flux, to be used as a sanity check against the measured value from a dataset.","category":"page"},{"location":"changelog.html#Half-pixel-offset","page":"Changelog","title":"Half-pixel offset","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"Has now been added to the code. This is a result from that RADMC synthesizes an image centered on (0,0), while the FFT routine expects the image to be centered on the middle of the central pixel. The only change you should see is a small, half-pixel sized offset in mu_RA and mu_DEC.","category":"page"},{"location":"changelog.html#Visualizing-the-tau1-surface","page":"Changelog","title":"Visualizing the tau=1 surface","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"This functionality originally provided in RADMC is now exposed via DiskJockey to visualize the tau = 1 (or other value) surface.","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"$ DJinitialize.jl && tausurfmodel.jl && plot_tausurf.jl","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"This also introduces the TausurfImage type in src/image.jl. This is useful to see whether the tau=1 surface is in front of or behind the midplane of the disk, projected on the sky.","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"It will be more useful to plot this in 3D, however. ParaView export is hopefully coming in a future version.","category":"page"},{"location":"changelog.html#Vertical-temperature-gradient","page":"Changelog","title":"Vertical temperature gradient","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"We now include support for fitting a vertical temperature gradient, via the vertical model type. We follow the parameterization in Williams and Best 14.","category":"page"},{"location":"changelog.html#model.convert_vector","page":"Changelog","title":"model.convert_vector","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"This routine is to simplify to ingesting kwargs, enabling easier selection of model types and parameters.","category":"page"},{"location":"changelog.html#User-defined-priors","page":"Changelog","title":"User-defined priors","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"As an experimental feature, it is now possible to assign user defined priors. This will require you to write some Julia code, but shouldn't be that difficult. An example is in assets/prior.jl, which will be read automatically from the current working directory. The main idea is to make it easier to assign disk-specific priors (i.e., constrain the disk gas mass to a specific value, or disk position, etc...).","category":"page"},{"location":"changelog.html#Makefiles","page":"Changelog","title":"Makefiles","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"Now, we include a makefile that should be copied to each source directory. In a typical analysis workflow, there isn't need to regenerate each intermediate product repeatedly. Details are in the cookbook.","category":"page"},{"location":"changelog.html#Script-renaming","page":"Changelog","title":"Script renaming","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"To prevent these scripts from cluttering a users namespace when adding to their PATH, we've prefixed most things with DJ_. Moreover, for most tasks, the users will not need to run these tasks directly, but will just use the Makefile.","category":"page"},{"location":"changelog.html#model.Grid","page":"Changelog","title":"model.Grid","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"Grid type initialization now relies upon a dictionary.","category":"page"},{"location":"changelog.html#Version-0.1.2","page":"Changelog","title":"Version 0.1.2","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"The package is now named DiskJockey (previously JudithExcalibur). Check out the new logo!","category":"page"},{"location":"changelog.html#Installation","page":"Changelog","title":"Installation","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"The README now provides installation instructions for tagged releases. Rather than requiring the user to install it separately, RADMC-3D is now installed automatically as part of the installation process.","category":"page"},{"location":"changelog.html#UVHDF5","page":"Changelog","title":"UVHDF5","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"Conversion from UVFITS and CASA measurement set was previously handled by scripts in this repository. However, this import and export capability has be standardized via the UVHDF5 package. Please see that package for any issues with import and export.","category":"page"},{"location":"changelog.html#Travis-integration","page":"Changelog","title":"Travis integration","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"Now the builds are tested on travis-ci, which should hopefully increase stability for the development cycle.","category":"page"},{"location":"changelog.html#EnsembleSampler","page":"Changelog","title":"EnsembleSampler","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"There is now an expand_walkers.py script, designed to add the dpc dimension to the sampling routine from an ensemble of walkers used on a posterior with distance fixed.","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"Now the ensemble sampler takes an optional function, to be called at the end of each loop as func(sampler, outdir)","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"function run_schedule(sampler::Sampler, pos0, N::Int, loops::Int, outdir, func::Function=nothing)","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"See the src/EnsembleSampler.jl file for more details. This is primarily in support of the next feature...","category":"page"},{"location":"changelog.html#Plotly-script","page":"Changelog","title":"Plotly script","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"If you run the sampling script as","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"$ venus.jl --plotly","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"Then after the completion of each sampling loop, this will create a plotly walkers plot corresponding to the name entry in config.yaml. This allows easy monitoring of many different chains that might be running on a cluster.","category":"page"},{"location":"changelog.html#DJInitialize.jl","page":"Changelog","title":"DJInitialize.jl","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"(Previously JudithInitialize.jl). Now this initialization script can easily spit out an exclude array so that fewer channels can be fit during initial testing.","category":"page"},{"location":"changelog.html#Cavity-model-2","page":"Changelog","title":"Cavity model","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"By initializing a directory with","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"$ DJInitialize.jl --new-project=cavity","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"you can start exploring the cavity model, which has an exponential taper inside of some radius, r_cav.","category":"page"},{"location":"changelog.html#gridding.jl","page":"Changelog","title":"gridding.jl","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"gridding.jl now exports a corrfun(img::SkyImage) routine, in addition to corrfun!(img::SkyImage). This new function returns a corrected image as a copy, leaving the original image in the arguments unchanged. This is useful for plotting and debugging scripts so that you don't need to copy the image manually.","category":"page"},{"location":"changelog.html#visibilities.jl","page":"Changelog","title":"visibilities.jl","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"FullModelVis now has a - method, which can be used to subtract two sets of dense visibilities.","category":"page"},{"location":"changelog.html#image.jl","page":"Changelog","title":"image.jl","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"Image now has a - method, which can be used to subtract two images.","category":"page"},{"location":"changelog.html#config.yaml-copied-to-output-directory","page":"Changelog","title":"config.yaml copied to output directory","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"Now venus.jl will move a copy of your config.yaml file to the output directory. This creates an automatic record of what parameters you ran with, which will undoubtedly be useful when reviewing previous runs sometime in the near future. Default values in the initial config.yaml files have also been updated.","category":"page"},{"location":"changelog.html#plot_baselines.jl","page":"Changelog","title":"plot_baselines.jl","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"Will generate a plot of where your dataset has sampled the UV plane. Also will print out an average velocity of the dataset, to allow a good starting guess for the vel parameter.","category":"page"},{"location":"changelog.html#Version-0.1.1","page":"Changelog","title":"Version 0.1.1","text":"","category":"section"},{"location":"changelog.html#Model-specification","page":"Changelog","title":"Model specification","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"New implementation of models through parameter types in model.jl. Instead of separate model files for each new parameterization, which duplicated a lot of code and made things difficult to maintain, we are now collating all model types in model.jl by their parameters. We have created the AbstractParameters umbrella type, with subtypes ParametersStandard, ParametersTruncated, and ParametersCavity. Previous model specification routines like Sigma(r::Float64, pars::Parameters) (surface density) are now have overloaded methods for different models based upon these parameter types","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"Sigma(r::Float64, pars::ParametersStandard)\nSigma(r::Float64, pars::ParametersTruncated)\nSigma(r::Float64, pars::ParametersCavity)","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"And routines that are general to all models (e.g. velocity specification) are denoted by","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"velocity{T}(r::T, pars::AbstractParameters)","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"Note that model types cavity and truncated are still experimental and likely to change.","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"To go along with this change, I have updated the automatic generation of the config.yaml file to include new fields like model: standard. Within the config.yaml file, items in the parameters dictionary are now simply a single Float64 number, not an array of [starting, jump] like it was previously.","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"model.jl now handles the implementation of priors, that dispatch off of the parameter types. This greatly streamlines the function fprob in venus.jl.","category":"page"},{"location":"changelog.html#One-off-model-synthesis-and-plotting","page":"Changelog","title":"One-off model synthesis and plotting","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"I've simplified synthesizing and plotting of models. What was previously plot_model.jl is now split into synthesize_model.jl and plot_chmaps.jl.","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"Added new plot_moments.jl script which plots the zeroth-moment image. Soon it will plot first moment as well.","category":"page"},{"location":"changelog.html#MCMC-Sampling","page":"Changelog","title":"MCMC Sampling","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"The specification of parameter types allowed me to greatly simplify the MCMC sampling code into a single script, venus.jl. I have moved previous sampling scripts to the attic/ directory.","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"Created InitializeWalkers.ipynb that is copied to new directory to help specify walker starting positions. The user edits this with a Jupyter/IPython notebook.","category":"page"},{"location":"changelog.html#New-Cookbook-available","page":"Changelog","title":"New Cookbook available","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"We now have a Cookbook for AK Sco, check it out to get started!","category":"page"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"plot_walkers.py now includes ability to determine highest density interval for quoting credible intervals and should automatically label the parameters after reading from config.yaml.","category":"page"},{"location":"changelog.html#Version-0.1.0","page":"Changelog","title":"Version 0.1.0","text":"","category":"section"},{"location":"changelog.html","page":"Changelog","title":"Changelog","text":"Initial commit on the new versioning roadmap.","category":"page"},{"location":"priors.html#Priors","page":"Priors","title":"Priors","text":"","category":"section"},{"location":"priors.html","page":"Priors","title":"Priors","text":"When fitting certain disks, it may be worthwhile to include new information from separate analyses. For example, when fitting multiple CO transitions, it may be worthwhile to make priors that constrain the temperature profile.","category":"page"},{"location":"priors.html","page":"Priors","title":"Priors","text":"Because flexible priors like these are difficult to \"hard-code\" into the package, there is an additional functionality that allows the user to write their own prior, which will overwrite the default prior in the package.","category":"page"},{"location":"priors.html","page":"Priors","title":"Priors","text":"You can copy a sample stub to your current working directory via","category":"page"},{"location":"priors.html","page":"Priors","title":"Priors","text":"$ DJInitialize.jl --prior","category":"page"},{"location":"priors.html","page":"Priors","title":"Priors","text":"Then, open this file with your favorite text editor. It is important that you mimic the exact same function call as in src/model.jl.","category":"page"},{"location":"formats.html#File-Formats","page":"Formats","title":"File Formats","text":"","category":"section"},{"location":"formats.html","page":"Formats","title":"Formats","text":"Interferometric data from reduction software like CASA or MIRIAD is generally stored in measurement sets (*.ms) or FITS files (*.fits), and usually contains a lot of ancillary data unnecessary for a dynamical mass measurement (or fitting in the UV plane in general). To reduce dependency on these outside programs and overall memory footprint, we have made it so that all of the Julia code only interfaces with the minimal necessary visibility data stored in an HDF5 file.","category":"page"},{"location":"formats.html","page":"Formats","title":"Formats","text":"The key Julia code used to read this file is provided in /src/visibilities.jl which reads the HDF5 file and stores each channel in an array of DataVis instances. For example, this data.hdf5 file contains the following datasets in arrays of (nrows, ncols) form. nchan is the number of channels in the dataset, nvis is the number of complex visibilities in the measurement set.","category":"page"},{"location":"formats.html","page":"Formats","title":"Formats","text":"The format of this datafile is as follows:","category":"page"},{"location":"formats.html","page":"Formats","title":"Formats","text":"data.hdf5\n  lams # [μm] (nchan) Wavelength (in microns) corresponding to channel\n  uu # [kλ] (nchan, nvis) Vectors of the u locations in kilolambda\n  vv # [kλ] (nchan, nvis) Vectors of the v locations in kilolambda\n  real # [Jy] (nchan, nvis) real component of the complex visibilities\n  imag # [Jy] (nchan, nvis) imaginary component of the complex visibilities\n  invsig # [1/Jy] (nchan, nvis) the inverse of sigma for each visibility (1/sigma)","category":"page"},{"location":"formats.html","page":"Formats","title":"Formats","text":"and an example datafile is provided for AK Sco, available for download here. The invsig field may seem like an non-traditional way to store visibility weights (typically measured in [1/Jy^2]), but enables quick computation of the chi^2 statistic via Julia's sum(abs2,...) routine.","category":"page"},{"location":"dynamical_mass_intro.html#Understanding-disk-based-dynamical-mass-measurements","page":"Introduction","title":"Understanding disk-based dynamical mass measurements","text":"","category":"section"},{"location":"dynamical_mass_intro.html","page":"Introduction","title":"Introduction","text":"Mass is the fundamental property that determines a star's fate. Compared to the masses of their older cousins on the main sequence, however, the masses of young pre-main sequence stars are relatively uncertain. Fortunately, young stars have a unique advantage that we can exploit to precisely infer their mass: many often host a protoplanetary disk made of gas and dust, the site of future and ongoing planet formation. By modeling the rotation of this disk, we can dynamically \"weigh\" the host star(s). Circumstellar disks are typically mm-bright, which means that interferometers like the Atacama Large Millimeter Array (ALMA) and the Submillimeter Array (SMA) are ideal instruments for deriving stellar masses.","category":"page"},{"location":"dynamical_mass_intro.html","page":"Introduction","title":"Introduction","text":"In this short intro, I will explain how we can use the kinematic fingerprint of the disk–imprinted by disk rotation–to derive precise estimates of the stellar mass.","category":"page"},{"location":"dynamical_mass_intro.html#Disk-geometry-and-rotation","page":"Introduction","title":"Disk geometry and rotation","text":"","category":"section"},{"location":"dynamical_mass_intro.html","page":"Introduction","title":"Introduction","text":"Astronomers typically model the structure of these protoplanetary disks as an axisymmetric disk with radial surface density defined by a power law and vertical structure set by hydrostatic equilibrium. As we will see, the orientation of the disk relative to us has a profound effect on what we observe. We define the inclination of the disk i as the angle between the disk angular momentum axis and the observer: 0^circ inclination means the disk is viewed face-on (appearing on the sky as a circle), while 90^circ inclination means the disk is viewed edge-on (appearing on the sky as a thin line).","category":"page"},{"location":"dynamical_mass_intro.html","page":"Introduction","title":"Introduction","text":"(Image: disk)","category":"page"},{"location":"dynamical_mass_intro.html","page":"Introduction","title":"Introduction","text":"The disk orbits the central stellar mass under the force of gravity, yielding velocities dictated by Kepler's law. Although there is evidence that due to pressure support gas disks rotate at slightly sub-Keplerian speeds, creating a headwind for any larger dust aggregates and solids (the meter-sized barrier), this effect is negligible when determining stellar mass. For more information about disk structure, check out the lecture notes by Phil Armitage.","category":"page"},{"location":"dynamical_mass_intro.html#Disk-emission-mechanisms","page":"Introduction","title":"Disk emission mechanisms","text":"","category":"section"},{"location":"dynamical_mass_intro.html","page":"Introduction","title":"Introduction","text":"Active young stars and their circumstellar disks can emit radiation at a host of wavelengths from the X-ray to the radio. When observing at sub-mm and radio wavelengths, there are two main sources of emission: Thermal continuum emission from the dust and spectral line emission from molecular species like carbon monoxide (CO).","category":"page"},{"location":"dynamical_mass_intro.html","page":"Introduction","title":"Introduction","text":"Owing to the high spatial resolution of an interferometer, it is possible to spatially resolve many circumstellar disks. If we set the frequency sampling finely enough, then we will have a dataset that is both spatially resolved (an image showing emission on many scales) and spectrally resolved (an image for every frequency we observe). This set of images is called a data cube or a series of channel maps.","category":"page"},{"location":"dynamical_mass_intro.html#Dust-emission","page":"Introduction","title":"Dust emission","text":"","category":"section"},{"location":"dynamical_mass_intro.html","page":"Introduction","title":"Introduction","text":"The intensity of continuum emission from the dust is related to the density and temperature of the emitting material. Because dust emission spans a continuum of frequencies, channel maps with fine frequency spacing yield little additional information–-typically these are summed together to yield greater sensitivity. Below is a movie showing what the dust emission looks like as we vary some of the key disk parameters: the radius of the disk, the inclination of the disk, and the stellar mass (stellar flux is kept fixed). In the movie, each parameter starts at an intermediate value, is then decreased to a minimum value, then increased to a maximum value, and then decreased back to the starting value. In this movie, the changes you will notice are due to variations in the radius and inclination of the disk.","category":"page"},{"location":"dynamical_mass_intro.html","page":"Introduction","title":"Introduction","text":"(Image: dust video)","category":"page"},{"location":"dynamical_mass_intro.html#Spectral-line-emission","page":"Introduction","title":"Spectral line emission","text":"","category":"section"},{"location":"dynamical_mass_intro.html","page":"Introduction","title":"Introduction","text":"When we observe the disk in narrow frequency channels at the location of spectral line emission, like CO J=2-1, we see the kinematic fingerprint of the disk. Each image shows the disk emission at a specific frequency, corresponding to the blue-shift (-velocity) or red-shift (+velocity) of the CO line, due to the projected velocity along the line of sight.","category":"page"},{"location":"dynamical_mass_intro.html","page":"Introduction","title":"Introduction","text":"Why the morphology of the line emission appears as it does isn't immediately obvious. Primarily, the shape of the emission is a function of the Keplerian rotation: the inner part of the disk rotates faster than the outer part of the disk and thus imparts a more substantial velocity shift to the line emission from these regions of the disk.","category":"page"},{"location":"dynamical_mass_intro.html","page":"Introduction","title":"Introduction","text":"As the parameters of the disk change, the projected velocity can change dramatically. For example, compare the difference between i approx 0^circ and i approx 90^circ! If the disk is more inclined towards face on (0^circ), the projection of the velocity along the line of sight will reduced and we will see more emission concentrated around 0 km/s.","category":"page"},{"location":"dynamical_mass_intro.html","page":"Introduction","title":"Introduction","text":"(Image: Gas Video)","category":"page"},{"location":"dynamical_mass_intro.html#Interferometers-measure-complex-visibilities","page":"Introduction","title":"Interferometers measure complex visibilities","text":"","category":"section"},{"location":"dynamical_mass_intro.html","page":"Introduction","title":"Introduction","text":"Although we may be used to looking at emission in the image plane, interferometers measure the Fourier transform of the sky brightness in the visibility plane. This next movie shows what the Fourier transform of each channel map looks like. As you can see, the Fourier transform looks quite different from the image.","category":"page"},{"location":"dynamical_mass_intro.html","page":"Introduction","title":"Introduction","text":"(Image: Visibilities Video)","category":"page"},{"location":"dynamical_mass_intro.html","page":"Introduction","title":"Introduction","text":"This Fourier plane is sampled according to the baselines formed between antennae separations. Below is a typical sampling pattern for an observation with the SMA.","category":"page"},{"location":"dynamical_mass_intro.html","page":"Introduction","title":"Introduction","text":"(Image: UV Spacings)","category":"page"},{"location":"dynamical_mass_intro.html","page":"Introduction","title":"Introduction","text":"Every dot represents a sampling of the Fourier transform in the UV plane. Some of the samplings are spaced so close together in space that they smear together into a line.","category":"page"},{"location":"index.html#DiskJockey.jl-Documentation","page":"Home","title":"DiskJockey.jl Documentation","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"DiskJockey.jl is a Julia package designed for forward-modeling radio observations of the dust and gas in protoplanetary disks using interferometers like the Submillimeter Array (SMA) and the Atacama Large Millimeter/Submillimeter Array (ALMA). Its main features consist of utilities to generate common protoplanetary disk structures, generate channel maps (using radiative transfer via RADMC-3D), Fourier transform and sample these at the baselines of the observations, and evaluate a visibility-based likelihood function. On top of this, there is a Julia version of the Affine Invariant Ensemble sampler to perform Markov Chain Monte Carlo Sampling of the posterior distribution.","category":"page"},{"location":"index.html#Citation","page":"Home","title":"Citation","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"If you use this code or a derivative of it in your research, we would really appreciate it if you cited the first paper in our series, Czekala et al. 2015 ApJ, 806 154C.","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"The source code for the project is on GitHub.","category":"page"},{"location":"index.html#Papers-using-DiskJockey","page":"Home","title":"Papers using DiskJockey","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"A Disk-based Dynamical Constraint on the Mass of the Young Binary AK Sco : Czekala et al. 2015 ApJ, 806 154C\nA Disk-based Dynamical Constraint on the Mass of the Young Binary DQ Tau : Czekala et al. 2016 ApJ, 818 156C\nALMA Measurements of Circumstellar Material in the GQ Lup System : Macgregor et al. 2017, ApJ, 835, 17M\nALMA Observations of the Young Substellar Binary System 2M1207 : Ricci et al. 2017 AJ, 154, 24R\nThe Architecture of the GW Ori Young Triple Star System and Its Disk: Dynamical Masses, Mutual Inclinations, and Recurrent Eclipses : Czekala et al. 2017, ApJ, 851, 132\nThe Degree of Alignment between Circumbinary Disks and Their Binary Hosts: Czekala et al. 2019, ApJ 883, 1, 22\nDynamical Masses and Stellar Evolutionary Model Predictions of M Stars: Pegues et al. 2021, ApJ 908, 1, 42\nA coplanar circumbinary protoplanetary disk in the TWA 3 triple M dwarf system: Czekala et al. 2021, ApJ accepted","category":"page"}]
}
